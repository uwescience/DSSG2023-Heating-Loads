{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseCase = pd.read_excel('../DSSG2023-Heating-Loads-Data/alanMitchellData/simulation_data/results_baseCase.xlsx', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "medRebate = pd.read_excel('../DSSG2023-Heating-Loads-Data/alanMitchellData/simulation_data/results_medRebate.xlsx', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "highRebate = pd.read_excel('../DSSG2023-Heating-Loads-Data/alanMitchellData/simulation_data/results_highRebate.xlsx', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "medFuelEsc = pd.read_excel('../DSSG2023-Heating-Loads-Data/alanMitchellData/simulation_data/results_medFuelEsc.xlsx', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "highFuelEsc = pd.read_excel('../DSSG2023-Heating-Loads-Data/alanMitchellData/simulation_data/results_highFuelEsc.xlsx', usecols=lambda x: x not in ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseCase['rebate_dol'] = 0\n",
    "baseCase['fuel_esc_rate'] = 0.03\n",
    "\n",
    "medRebate['rebate_dol'] = 2000\n",
    "medRebate['fuel_esc_rate'] = 0.03\n",
    "highRebate['rebate_dol'] = 8000\n",
    "highRebate['fuel_esc_rate'] = 0.03\n",
    "\n",
    "medFuelEsc['rebate_dol'] = 0\n",
    "medFuelEsc['fuel_esc_rate'] = 0.06\n",
    "highFuelEsc['rebate_dol'] = 0\n",
    "highFuelEsc['fuel_esc_rate'] = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScens = pd.concat([baseCase, medRebate, highRebate, medFuelEsc, highFuelEsc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allScens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScens = pd.get_dummies(allScens, columns=['City', 'Census_Area', 'Exist_Fuel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScens.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the df into input and output components\n",
    "Y = allScens['NPV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allScens_dummies = allScens.filter(regex = 'Census_Area_|Exist_Fuel_(?!Type)')\n",
    "allScens_numerics = allScens[['PCE', 'Sq_Ft', 'Capital_Cost', 'Elec_Use_Jan', 'Elec_Use_May', 'Design_Heat_Load', 'Design_Heat_Temp', 'COP', 'HP_Load_Frac', 'Fuel_Use_Chg', 'Elec_Use_Chg', 'Elec_Rate_Incremental', 'rebate_dol', 'fuel_esc_rate']]\n",
    "X = pd.concat([allScens_dummies, allScens_numerics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(max_depth = 5, n_estimators=250, learning_rate=0.5)\n",
    "#model = Lasso(alpha=1, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "grid['subsample'] = [0.5, 0.7, 1.0]\n",
    "grid['max_depth'] = [3, 7, 9]\n",
    "\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='neg_mean_absolute_error')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, Y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "print(\"The RMSE of the model is\", rmse)\n",
    "print(\"The MAE of the model is\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(allScens['NPV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), RandomForestRegressor())\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[1].coef_, columns=[\"Coefficients\"], index=X_train.columns\n",
    ")\n",
    "\n",
    "coefs.plot(kind=\"barh\", figsize=(9, 7))\n",
    "plt.title(\"Ridge model\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
